# Serve after softmax train

We can use `guild serve --print-model-info` to print information about
a saved model generated by a run. By default the latest run is used.

    >>> run("guild serve --print-model-info")
    - signature_defs:
        serving_default:
          inputs:
            inputs:
              dtype: DT_FLOAT
              shape: [-1, 784]
              tensor: Placeholder:0
          method_name: tensorflow/serving/predict
          outputs:
            classes:
              dtype: DT_INT64
              shape: [-1]
              tensor: ArgMax_2:0
            probabilities:
              dtype: DT_FLOAT
              shape: [-1, 10]
              tensor: Softmax:0
      tags: [serve]
      tensorflow_git_version: v1.6.0...
      tensorflow_version: 1.6.0
    <exit 0>

`guild serve` will load the saved model generated by the softmax
training and use it to make predictions. The default behavior, shown
below, is to serve the latest run.

    >>> run("echo Testing serve && "
    ...     "guild serve --test serving_default --test-json-instances %s"
    ...     % sample("serve/mnist-instances.json"))
    Testing serve
    ...
    {'predictions': [{'classes': 3,
                      'probabilities': [...]},
                     {'classes': 4,
                      'probabilities': [...]}]}
    <exit 0>
