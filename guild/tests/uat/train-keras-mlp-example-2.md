# Train Keras MLP example 2

In this test we run the mnist_mlp example as an operation defined in a
Guild file.

The example is in the `keras` directory.

    >>> cd("examples/keras")

Here are the operations available:

    >>> run("guild ops mlp-mnist", ignore="Refreshing")
    mlp-mnist:train  Train MLP on MNIST
    <exit 0>

Train `mlp-mnist`:

    >>> run("guild run mlp-mnist:train -y --no-gpus epochs=1")
    Limiting available GPUs (CUDA_VISIBLE_DEVICES) to: <none>
    Using TensorFlow backend.
    60000 train samples
    10000 test samples
    ...
    Total params: 669,706
    Trainable params: 669,706
    Non-trainable params: 0
    ...
    Epoch 1/1
    ...
    60000/60000 ...
    test_loss: ...
    test_acc: ...
    <exit 0>

Here are the files and scalars generated by the run:

    >>> run("guild runs info --files --scalars")
    id: ...
    operation: mlp-mnist:train
    status: completed
    started: ...
    stopped: ...
    marked: no
    label: epochs=1
    run_dir: ...
    command: ...
    exit_status: 0
    pid:
    flags:
      batch_size: 128
      epochs: 1
    scalars:
      acc: ... (step 0)
      loss: ... (step 0)
      val_acc: ... (step 0)
      val_loss: ... (step 0)
      test_acc: ... (step 0)
      test_loss: ... (step 0)
    files:
      events.out.tfevents...
    <exit 0>
